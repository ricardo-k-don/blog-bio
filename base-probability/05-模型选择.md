# 模型选择

## 1. 拟合程度

当一个模型与当初用于学习其参数的数据集拟合得非常好，但在拟合其他数据集时却非常糟糕时，即为过拟合（overfitting）。这是统计学和机器学习中一个非常普遍的问题。

描绘过拟合问题的一个非常有用的方法是认为数据集有两个组成部分：信号和噪声。信号是我们想从数据中学习的任何东西。而噪声则是没有用的，它是测量误差、数据生成或采集方式的限制、损坏的数据等的产物。当一个模型非常灵活地学习了噪声，有效地隐藏了信号时，它就会出现过拟合。

在实际应用时，若样本容量不远远大于样本的特征维度，很可能造成过拟合，对这种情况，有下面三个解决方案：

1. 加数据
2. 降维
3. 正则化

但在复杂度的另一个极端，我们有 0 阶的模型。这个模型只是一个变量$y$伪装成线性模型的高斯模型。这个模型只是捕捉到了因变量的均值，而与变量$x$的值完全无关。我们说这个模型欠拟合。

理想情况下，我们希望有一个既不过度拟合也不过度拟合数据的模型。故，在一般情况下，我们会面临一个权衡，我们必须以某种方式优化或调整我们的模型。这种权衡通常用偏差和方差来讨论。

- 高偏差是模型适应数据能力低的结果。高偏差会导致模型错过相关的模式，因此会导致欠拟合。
- 高方差是模型对数据中的细节高度敏感的结果。高方差会导致模型捕捉到数据中的噪声，因此会导致过拟合。

0 阶模型是具有较高偏差（和较低方差）的模型，因为它偏向于在变量的均值处返回一条扁平的线，而不管变量的值是多少。5 阶模型是具有较高方差（和较低偏差）的模型。

高偏差的模型有更多的偏见或惯性，而高方差的模型是一个更开放的模型。太过偏见的问题是你没有能力去接纳新的证据；太过开放的问题是你最终会相信一些无厘头的东西。一般来说，当我们增加其中一个条件时，我们就会减少另一个条件，从而导致我们的偏差 - 方差权衡。

### 1.1. Occam 剃刀

通过进行后验预测检查，我们希望能更好地掌握模型的局限性，或尝试改进模型。若我们有一个以上的模型，我们可使用后验预测检查来比较它们。下面的例子中，二次模型似乎做得更好，但线性模型也不差。

![fit](rethinking/images/ch05/dummy-fit.pngpng)

下图显示了数据的均值和四分位数范围（interquartile range，IQR），以及线性和二次方模型的均值和四分位数范围。在此图中，我们对每个模型的后验预测样本进行平均。我们可看到，两个模型的均值（平均）重现得很好，分位数范围也不是很偏，但，有一些小的差异，在实际问题中，可能值得我们注意。我们可做很多不同的图来探索一个后验预测分布。例如，我们可绘制均值和四分位数范围的分散度。

![IQR](rethinking/images/ch05/dummy-iqr.pngpng)

上图中，黑色虚线代表了从数据中计算出来的统计量（均值或 IQR）。因为我们有一个单一的数据集，故我们有一个单一的统计值（而不是分布）。曲线代表了从后验预测样本计算出来的均值（左图）或四分位数范围（右图）的分布。我们通过比较模拟数据和实际数据来计算 p 值。对于这两组数据，我们计算出一个汇总统计量（在本例中为均值或 IQR），然后计算出模拟数据的汇总统计量等于或大于数据的比例。若数据和模拟结果一致，我们应该期待一个 0.5 左右的 p 值，否则我们就存在一个有偏差的后验预测分布。

![IQR](rethinking/images/ch05/dummy-mean-iqr.pngpng)

贝叶斯的 p 值基本上和频率主义一样，但只是得到一个度量后验预测拟合度的数字的方法。

$$
\text{Bayesian p-value} ≜ p(T_\mathrm{sim} > T_\mathrm{obs} | y)
$$

即，我们得到的模拟统计量$T_\mathrm{sim}$的概率等于或比数据中的统计量$T_\mathrm{obs}$更极端。其中，$T$几乎可是任何提供数据摘要的东西。$T$是统计量，即左图的均值，右图的标准差。这些$p$值是贝叶斯的，因为对于采样分布，我们使用的是后验预测分布。同时注意到，我们并不以任何零假设为条件；我们有整个$θ$的后验分布，我们是以观察到的数据为条件的。我们并没有使用任何预定义的阈值来声明统计显著性，也没有进行设检验，我们只试图计算一个数字来评估后验分布对数据集的适应性。

在进行选择时，有一个被称为 Occam 剃刀（Occam's razor）的指导原则：若对同一现象有两种或更多相同的解释，我们应该选择较简单的解释。

在比较模型时，我们一般应该考虑的另一个因素是它们的准确性，也就是模型对数据的拟合程度。我们已经看到了一些精度的度量标准，如决定系数$R^2$，我们可把它解释为线性回归中可解释方差的比例，也可说后验预测检查是基于数据的准确性的想法。

![occam](rethinking/images/ch05/occam.pngpng)

### 1.2. 精度

要度量模型的准确性，我们需要一个更原则的方法，一方面要考虑准确性，另一方面要考虑简单性。为此，我们需要引入几个新概念。前两个概念是

- 样本内精度：用于拟合模型的数据所测量的精度。
- 样本外精度：不用于拟合模型的数据所测量的精度，这也被称为预测准度（predictive accuracy）。

对于任何数据和模型的组合，平均而言，样本内精度将小于样本外精度。故，使用样本内精度可能会愚弄我们，使我们认为我们有一个比我们真正拥有的更好的模型。出于这个原因，样本外测量比样本内测量更受欢迎。但，一般来说，这有一个问题。我们需要有能力留出一部分数据，不是为了拟合模型，而是为了测试它。这对于大多数分析师来说，往往是一种奢侈。为了规避这个问题，人们花了很多精力设计出只用样本内数据估计样本外预测精度的方法。这种方法有两种

- 交叉验证：这是一种经验策略，基于将现有数据分为子集，以另一种方式用于拟合和评估。
- 信息标准：这是几个相对简单的表达式的总称，这些表达式可被认为是近似于我们通过交叉验证可得到的结果的方法。

在大多数情况下，交叉验证是一个简单的有效的解决方案。为评估一个模型，我们把数据分成若干部分，让这些部分或多或少地保持相等（在大小上，有时也在其他特征上，例如，相等数量的类）。然后，我们用其中的一部分来训练模型，剩下的部分用于测试它。然后，我们系统地重复这个过程，从训练集中留下不同的部分，并将这部分作为测试集。这就是所谓的 _k_-折交叉验证。当 _k_ 等于数据点的数量时，我们就会得到所谓的留一交叉验证（leave-one-out cross-validation，LOO-CV）。有时，在做 LOO-CV 时，若我们的数据点数量多到令人望而却步，则轮次的数量可能会少于数据点的总数。

![cross validation](rethinking/images/ch05/cross-val.pngpng)

交叉验证是一个非常简单有用的想法，但，对于一些模型或大量数据来说，交叉验证的计算成本可能超出了我们的可能性。很多人试图提出一些更简单易算的量，来近似交叉验证得到的结果，且在交叉验证不是那么直接的情况下也能发挥作用。

### 1.3. 偏离度

度量一个模型与数据拟合程度的通用的测量方法是计算对数似然。

$$
∑\log p(y_i ∣ θ)
$$

当似然是正态的时候，这与二次平均误差成正比。在实际工作中，由于历史原因，人们通常不直接使用对数似然，而是使用一个称为偏离度（deviance）的量。

$$
-2 ∑\log p(y_i ∣ θ)
$$

偏离度对于贝叶斯主义者和非贝叶斯主义者均是一样的；不同的是，在贝叶斯框架下，$θ$是从后验中估计出来的，且，像任何从后验中得出的数量一样，它有一个分布。相反，在非贝叶斯环境下，$θ$是一个点估计。

## 2. 信息准则

信息标准（information criterion）是一系列不同的且有某种关联的工具，用于比较模型在数据上的拟合程度，同时通过惩罚项调整模型的复杂性。

### 2.1. AIC & BIC

AIC（Akaike information criterion）一个非常著名的、被广泛使用的信息标准，特别是对于非贝叶斯来说，定义如下

$$
\mathrm{AIC} = -2 ∑\log p(y_i |θ̂_\mathrm{MLE}) +2 p_\mathrm{AIC}
$$

其中，$p_\mathrm{AIC}$只是参数的数量。对于非贝叶斯来说，MLE 是一种常见的做法，一般来说，当使用扁平先验时，相当于 MAP 估计。$-2$ 的存在是由于历史原因。

从实践的角度来看，重要的观察是，第一项考虑了模型对数据的拟合程度，第二项惩罚了复杂模型。故，若两个模型同样能解释数据，但一个模型的参数比另一个多，AIC 告诉我们应该选择参数较少的那个模型。对于非贝叶斯方法来说，它的效果很好，但在其他方面就有问题了。原因之一是它没有使用后验，因此它抛弃了估计中不确定性的信息；它还设了扁平的先验，因此这种测量方法与信息性和弱信息性先验不兼容。

另一种信息标准是 BIC（Bayesian information criterion），它类似于逻辑回归。这个名字可能会让人误解。BIC 的提出是为了纠正 AIC 的一些问题。但 BIC 并不是真正的贝叶斯主义，事实上和 AIC 很相似。它亦假设扁平先验，并使用 MLE。

### 2.2. WAIC

这是完全贝叶斯版本的 AIC。与 AIC 一样，WAIC（widely applicable information criterion）有两项：一个是拟合程度，一个是惩罚。

$$
\mathrm{WAIC} = -2*\mathrm{IPPD} + 2*p_\mathrm{WAIC}
$$

展开得

$$
\mathrm{WAIC} = -2 ∑\log \bigg(\frac{1}{S} ∑_{s = 1}^S p(y_i ∣ θ^s) \bigg) +
2 ∑(\mathrm{V}_{s = 1}^S \log p(y_i ∣ θ^s))
$$

表达式中的两项看起来非常相似。第一项，IPPD（log point-wise predictive density），是计算$S$后验样本上的平均似然。我们对每个数据点进行计算，然后取对数，在所有数据点上求和。对比偏离度，其计算考虑到了后验。故，若我们接受计算对数似然是度量模型拟合度是否合适的好方法，则从后验计算它就是贝叶斯方法的逻辑路径。

观测数据的 IPPD 是对未来数据的 LDPD 的高估。故，引入第二个项来修正高估。第二个项计算对数似然在后验样本上的方差。我们对每个数据点进行计算，然后对所有数据点进行加和。有效参数的数量越大，后验的分布就越大。当我们在一个模型中加入结构时，如用信息/正则化前值或层次依赖关系，我们就会限制后验，从而与类似的非正则化或结构化程度较低的模型相比，减少有效参数的数量。

> 从实际的角度来看，我们更喜欢较低的 WAIC 值。

![WAIC](rethinking/images/ch05/waic-comparison.pngpng)

- 空圈代表 WAIC 值，与之相关的黑色误差条是 WAIC 的标准差值。
- 为了便于与其他 WAIC 值进行比较，最低的 WAIC 值也用垂直的灰色虚线表示。
- 填充的黑点是每个模型的样本内偏差，对于 WAIC 来说，它与对应的 WAIC 值相差 2p × WAIC。
- 三角形表示该模型与排名靠前模型的 WAIC 差值，灰色误差条表示每个模型排名靠前的 WAIC 与 WAIC 差值的标准误差。

当计算 WAIC 或 LOO 时，您可能会收到一条警告信息，表明任何一种计算的结果均是不可靠的。这个警告是根据经验确定的临界值而发出的。虽然它不一定有问题，但它可能表明这些度量的计算有问题。若这种情况发生，首先要确保你有足够的样本，且有一个混合良好的可靠样本。若你仍然得到这些信息，LOO 方法的作者建议使用一个更稳健的模型，如学生 _t_-分布而不是高斯分布。若这些建议都不奏效，则您可能需要考虑使用另一种方法，如直接执行 _k_-折交叉验证。更笼统的说，WAIC 和 LOO 只能帮助你在给定的模型集中进行选择，但它们不能帮助决定一个模型是否真的是特定问题的好解决方案。出于这个原因，WAIC 和 LOO 应该辅以后验预测检查，以及任何其他信息和测试。

### 2.3. PSIS

在某些一般条件下，WAIC 和 LOO 都会渐进收敛。主要的想法是可通过重新适当加权似然来近似 LOO-CV。问题是结果是不稳定的。为了解决这个问题，人们引入了一种新的方法，帕累托平滑重要性采样（Pareto smoothed importance sampling，PSIS）的技术。PSIS 是一种高效逼近 LOO-CV 结果的方法，但不进行 _k_ 次迭代。它可用于计算更可靠的 LOO 估计。它不是一个信息标准，但实际上提供的结果与 WAIC 非常相似，数值越低，估计模型的预测精度越高。

> `ArviZ` 默认采用 PSIS-LOO 代替 LOO。

## 3. 模型平均

模型选择因其简单性而吸引人，但会丢弃模型中的不确定性信息。这在某种程度上类似于计算完整的后验，然后只保留后验的均值；我们可能会对我们真正知道的东西过于自信。一种方法是进行模型选择，但报告并讨论不同的模型，以及计算出的信息标准值，它们的标准误差值，也许还包括后验预测检查。重要的是把所有这些数字和检验放在我们问题的背景下。另一种方法是充分接受模型比较中的不确定性，并进行模型平均。现在的想法是使用每个模型的加权均值来生成元模型（和元预测）。

### 3.1. 伪贝叶斯模型平均

计算每个模型权重的一种方法伪贝叶斯模型平均（pseudo Bayesian Modeling Averaging，pseudo-BMA），利用下式

$$
w_i = \frac{e^{\frac{1}{2} dE_i}}{∑^{M} e^{-\frac{1}{2} dE_{j}}}
$$

其中，$dE_i$是 i-esim 模型的 WAIC 值与 WAIC 最低的模型之间的差值。这里，可使用任何其他想要的信息标准来代替 WAIC，如 AIC。这个公式是一种启发式，通过 WAIC（或其他类似度量）来计算每个模型的相对概率。分母是一个标准化项，以确保权重相加为 1，类似 softmax 函数。

之所以称"伪"是因为真正的贝叶斯模型平均化将是使用边际似然而不是 WAIC 或 LOO。尽管如此，在模型比较和模型平均方面，都有理论和经验上的原因，更倾向于使用 WAIC 或 LOO 而不是边际似然。

> 使用 PyMC3，通过向 `az.compare` 函数传递 `method='pseudo-BMA'` 参数，可计算前面公式中表示的权重。这个公式的一个注意事项是，它没有考虑到计算$E_i$的值时的不确定性。假设是高斯近似，我们可计算每个$E_i$的标准误差。这些均是函数 `az.waic`，`az.loo` 和函数 `az.compare` 在传递 `method='pseudo-BMA'` 参数时返回的误差。我们还可通过使用贝叶斯自举法（Bayesian bootstrapping）来估计不确定性。这是比设正态性更稳健的方法。若你把 `method='BB-pseudo-BMA'` 传递给 `az.compare` 函数，PyMC3 可为你计算出这个值。

### 3.2. 堆叠分布

计算每个模型权重的另一种方法是预测分布的堆叠（stacking），其基本思想是通过最小化元模型和真实生成模型之间的散度（divergence）来组合元模型中的几个模型。当使用对数计分规则时，这相当于计算下式

$$
\max_n \frac{1}{n} ∑\log ∑_{k=1}^k w_k p(y_i | y_{-i}, M_k)
$$

其中，$n$是数据点的数量，$K$是模型的数量。为了强制求解，我们将$w$约束为$w_k ≥ 0$且$∑w_k = 1$。$p(y_i | y_{-i}, M k)$是$M_k$模型的留一预测分布。幸运的是，我们可使用 WAIC 或 LOO 来逼近精确的留一预测分布。

### 3.3. 其他

还有其他的方法来平均模型，如，明确地建立一个元模型，将所有感兴趣的模型作为子模型。我们可通过这样的方式建立这样的模型，对每个子模型的参数进行推理，同时计算每个模型的相对概率。

除了对离散模型进行平均外，我们有时还可想到它们的连续版本。一个有趣的例子是，想象我们有一个抛硬币的问题，我们有两个不同的模型：一个先验偏向于正面，另一个偏向于反面。一个连续的版本将是一个层次模型，其中的先验分布是直接从数据中估计出来的。这种层次模型包括了作为特例的离散模型。哪种方法更好？这取决于具体问题。

![Averaging](rethinking/images/ch05/averaging.pngpng)

## 4. 贝叶斯因子

在贝叶斯世界，评价和比较模型的一个常见的选择是 BF。由 Bayes 定理

$$
p(θ | y, M_k) = \frac{p(y ∣ θ, M_k) p(θ | M_k)}{p(y ∣ M_k)}
$$

其中，分母中的项称为边际似然（或证据）。在做贝叶斯推理的时候，我们不需要计算边际似然（或证据）这个归一化常数。但，对于模型比较和模型平均，边际似然是一个重要的量。

### 4.1. 定义

若我们的主要目的是从一组$k$的模型中只选择一个模型，也就是最好的模型，我们可只选择$p(y ∣ M_k)$最大的那个模型。作为一般规则，$p(y ∣ M_k)$是微小的数字，本身并不能告诉我们太多，就像信息标准一样，重要的是相对值。故，在实践中，人们经常计算两个边际可能性的比值，这就是所谓的贝叶斯因子（Bayesian factor，BF）。

$$
\mathrm{BF} = \frac{p(y ∣ M_0)}{p(y ∣ M_1)}
\tag{1.3}
$$

当$\mathrm{BF}>1$时，模型 0 比模型 1 更能解释数据。一些作者提出了带有范围的表格，以分散和方便解释。例如，下面的项目表显示了证据的强度，赞成模型 0，反对模型 1。

- 1 -3：传闻
- 3-10: 中等
- 10-30: 强烈
- 30-100: 非常强
- > 100：极端

若设所有的模型都具有相同的先验概率，则使用$p(y ∣ M_k)$来比较模型是完全可的。否则，我们必须计算后验概率。

$$
\underbrace{\frac{p(M_0 | y)}{p(M_1 | y)}}_{\text{posterior odds}}
= \underbrace{\frac{p(y ∣ M_0)}{p(y ∣ M_1)}}_{\text{Bayes factors}}
\underbrace{\frac{p(M_0)}{p(M_1)}}_{\text{prior odds}}
$$

通过仔细检查边际似然的定义，我们可了解它们的特性和实际使用的后果。

$$
p(y ∣ M_k) = ∫_{θ_k} p(y ∣ θ_k, M_k) p(θ_k, M_k) dθ_k
\tag{1.4}
$$

- 好的。参数多的模型比参数少的模型有更大的惩罚。BF 内置了 Occam 剃刀。直观的原因是，参数数量越多，先验相对于似然越分散。故，在计算上式中的积分时，你会得到一个更集中的先验值的小值。
- 坏的。计算边际似然一般来说是一项艰巨的任务，因为前面的公式是一个高维参数空间的高变量函数的积分。一般来说，这个积分需要使用或多或少的复杂方法进行数值求解。
- 丑陋的。边际似然值敏感地取决于先验的大小。

使用边际似然来比较模型是一个好主意，因为已经包含了对复杂模型的惩罚。同时，先验的改变会影响边际似然的计算。我们已经知道先验会影响计算，但这里的重点是敏感这个词。我们谈论的是先验的变化，这些变化将使$θ$的推理大致保持不变，但可能会对边际似然的值产生很大的影响。一般来说，拥有一个标准差为 100 的正态先验和拥有一个标准差为 1000 的正态先验是一样的。但，BF 会受到这类变化的影响。

许多作者指出，这里使用的推理方法，比假设检验方法更适合大多数问题。

### 4.2. 计算

BF 的计算可归纳为一个层次模型，其中，高层参数是一个指数，它被分配给每个模型，并从分类分布中采样。换句话说，我们同时执行两个（或多个）竞争模型的推理，我们使用一个离散变量，在模型之间跳跃。我们花在每个模型上的采样时间与$p(y ∣ M_k)$成正比。

> 为了在先验之间进行切换，使用 `pm.math.switch`。若这个函数的第一个参数值为真，则返回第二个参数，否则返回第三个参数。另外使用 `pm.math.eq` 函数来检查 `model_index` 变量是否等于 0。我们需要通过计算 `model_index` 变量来计算贝叶斯系数。注意，我们已经包含了每个模型的先验。

另一种计算贝叶斯系数的途径是使用一种称为 Sequential Monte Carlo（SMC）的采样方法。目前，我们只需要知道这个采样器计算边际似然的估计，作为副产品，我们可直接用于计算 BF。

当以我们的方式计算 BF 时，一个常见的问题是，若一个模型比另一个更好。根据定义，我们将花费更多的时间从它那里采样。这可能是个问题，因为我们可能会对其中一个模型进行过度采样。另一个问题是，参数的值会被更新，甚至当参数不用于拟合该模型时亦为如此。即，当选择模型 0 时，模型 1 中的参数会被更新，但由于它们不用于解释数据，故它们只会受到先验的限制。若先验太过模糊，就有可能当我们选择模型 1 时，参数值与之前接受的值相差太远，从而一步被拒绝。故，我们最终会出现采样的问题。若遇到这些问题，我们可对模型进行两个修改来提高采样。

- 理想情况下，我们可得到一个更好的采样两个模型，若他们是平等的访问，故我们可调整每个模型的先验（前一个模型中的 p 变量），以这样的方式，有利于较不利的模型，而不利于最有利的模型。这不会影响 BF 的计算，因为我们在计算中包含了先验。
- 使用伪先验。这个想法很简单：若问题是参数不受限制地漂移，当它们所属的模型没有被选中时，则有一个解决方案是尝试人为地限制参数。

### 4.3. 与信息准则

若我们取 BF 的对数，就可把边际似然的比值变成差值。比较边际似然的差差值似于比较信息标准的差异。此外，我们还可解释 BF，或更准确的说，边际似然。表示模型对数据拟合程度的项是似然部分，惩罚部分来自于对先验的平均。参数数量越多，与似然量相比，先验量越大，因此我们最终会从似然值很低的区域取均值。参数越多，先验就越被稀释或扩散，因此在计算证据时，惩罚也就越大。这就是人们说 Bayes 定理会导致复杂模型的自然惩罚的原因，即，Bayes 定理内置了 Occam 剃刀。

BF 对先验的敏感度比很多人意识到的要高。这就像在进行推理时，有一些实际上无关紧要的差异，在计算 BF 时，却变成了重要的。

回到抛硬币例子的数据定义，现在设置 300 个硬币和 90 个正面；这与之前的比例相同，但我们的数据多了 10 倍。然后，分别运行每个模型。

![model](rethinking/images/ch05/coin-bf.svgsvg)

通过添加更多的数据，我们几乎完全克服了之前的问题，现在两个模型的预测结果都差不多。用 30 个硬币和 9 个正面作为数据，我们看到的 BF 是 11，若我们用 300 个硬币和 90 个正面的数据重复计算，我们会看到 BF 是 25。贝叶斯系数是说模型 0 比模型 1 更受青睐，甚至比之前更受青睐。当我们增加数据时，模型之间的决定会变得更加清晰。这完全有道理，因为现在我们更确定模型 1 的先验与数据不一致。同时注意到，随着数据量的增加，两种模型都会在$θ$的值上达成一致；事实上，两种模型都能得到$θ$约 0.3. 故，若我们决定使用$θ$来预测新的结果，则从哪个模型中计算$θ$的分布几乎没有任何区别。

![BF](rethinking/images/ch05/coin-bf-forest.pngpng)

现在，让我们比较一下 WAIC 告诉我们什么。模型 0 的 WAIC 是 368.4，模型 1 的 WAIC 是 368.7。比实际差异更重要的是，若你再次计算数据的信息标准，也就是 30 个硬币和 9 个正面，你会得到类似于模型 0 的 WAIC ≈ 38.1 和模型 1 的 WAIC ≈ 39.5。即，当数据增加时，相对的差异会变得更小--对$θ$的估计越相似，信息标准估计的预测精度值就越相似。若用 LOO 代替 WAIC，你会观察到基本相同的情况。

|     |  waic   | waic_se |  p_waic  | n_samples | n_data_points | warning | waic_scale |
| :-: | :-----: | :-----: | :------: | :-------: | :-----------: | :-----: | :--------: |
|  0  | 38.1724 | 4.30795 | 0.756283 |   4000    |      30       |  False  |  deviance  |
|  1  | 39.4834 | 2.01241 | 0.691197 |   4000    |      30       |  False  |  deviance  |
|  2  | 368.366 | 13.461  | 0.922967 |   4000    |      300      |  False  |  deviance  |
|  3  | 368.741 | 12.4647 | 0.965218 |   4000    |      300      |  False  |  deviance  |

BF 关注的是哪个模型更好，而 WAIC（和 LOO）关注的是哪个模型会给出更好的预测。WAIC 和其他信息标准一样，以某种方式使用对数似然，而先验并不直接参与计算。先验只是间接参与，帮助我们估计$θ$的值，相反，BF 直接使用先验，因为我们需要在整个先验范围内平均似然。

![iqr](rethinking/images/ch05/coin-bf-iqr.pngpng)

## 5. 正则化

使用有信息量和弱信息量的先验是在模型中引入偏差的一种方式，若操作得当，这可能非常好，因为偏差可防止过拟合，从而有助于模型能够做出泛化良好的预测。这种在不影响模型对用于拟合的数据进行充分建模的情况下，加入一个偏置来减少泛化误差的想法被称为正则化（regularization）。正则化通常采取的形式是对模型中的参数进行较大值的惩罚。这是一种减少模型所能表示的信息的方式，从而减少模型捕获噪声而不是信号的机会。

在非贝叶斯统计学中，正则化思想的形式是对最小二乘法（LSE）的两种修改，称为岭回归和拉索回归。岭和拉索回归的经典版本对应的是单点估计，而贝叶斯版本则给出了一个完整的后验分布作为结果。

### 1.2. MLE

对数据集

$$
\mathscr{D} = \{(x_1, y_1), (x_2, y_2), ⋯, (x_N, y_N)\}
$$

记

$$
X = (x_1, x_2, ⋯, x_N)^{⊤}, Y = (y_1, y_2, ⋯, y_N)^{⊤}
$$

采用 LSE 来度量误差，有

$$
L(w) = ∑_{i=1}^n ∥w^{⊤} x_i - y_i∥^2_2
$$

又由于在概率上，线性回归模型可表示为

$$
y ∼ N(w^{⊤} x, σ^2)
$$

即 $y = w^{⊤} x + ϵ, ϵ ∼ N(0, σ^2)$。代入最大似然估计（MLE），得

$$
\begin{aligned}
L(w)
&= \log ∏_{i=1}^n p(y_i | x_i, w) \\
&= ∑_{i=1}^n \log(\frac{1}{\sqrt{2πσ}}e^{-\frac{(y_i - w^{⊤} x_i)^2}{2σ^2}})
\end{aligned}
$$

问题转化为

$$
\underset{w}{\mathrm{argmax}}\ L(w) = \underset{w}{\mathrm{argmin}}\ ∑_{i=1^n}(y_i - w^{⊤} x_i)^2
$$

由上，**在噪声为高斯分布的时候，MLE ≡ LSE**。

### 5.1. MAP

取先验分布 $w ∼ N(0, σ_0^2)$。于是

$$
\begin{aligned}
ŵ
&= \underset{w}{\mathrm{argmax}}\ p(Y|w)p(w) \\
&= \underset{w}{\mathrm{argmax}}\ \log p(Y|w)p(w) \\
&= \underset{w}{\mathrm{argmax}}\ (\log p(Y|w) + \log p(w)) \\
&= \underset{w}{\mathrm{argmin}}\ [(y- w^{⊤} x)^2 + \frac{σ^2}{σ_0^2} w^{⊤} w]
\end{aligned}
$$

> 这里利用了高斯分布的 MLE 的结果。

### 5.2. Ridge

岭回归可解释为对（线性模型的）$β$系数使用高斯分布，以很小标准差将系数推向零。

$$
ŵ = \underset{w}{\mathrm{argmin}}\ L(w)+λ w^{⊤} w \\
↓\\
\frac{∂}{∂w}L(w)+2λ w=0\\
↓\\
2𝑿^{⊤} Xŵ-2𝑿^{⊤} Y +2λ ŵ = 0\\
↓\\
ŵ =(𝑿^{⊤} X+λ𝑰)^{-1}𝑿^{⊤} Y
$$

可以看到，这个正则化参数和 MAP 结果不谋而合。利用 2-范数进行正则化不仅可以是模型选择$w$较小的参数，同时也可避免$𝑿^{⊤} X$不可逆的问题。

### 5.3. Lasso

拉索回归可解释为从一个$β$系数具有 LaPlace 先验的模型计算出的后验的 MAP。这种正则化会引起稀疏解。

从最小化损失的角度看，由于 ℓ1 项求导在 0 附近的左右导数都不是 0，因此更容易取到 0 解。另一个方面，ℓ1 正则化相当于：

$$
\underset{w}{\mathrm{argmin}}\ L(w) s.t. ∥w∥_1\lt C
$$

我们已经看到平方误差损失函数在 $w$ 空间是一个椭球，因此上式求解就是椭球和 $∥w∥_1=C$的切点，因此更容易相切在坐标轴上。

LaPlace 分布看起来类似于高斯分布，但它的第一导数在零处是不确定的，因为它在零处有一个非常尖锐的峰值。与高斯分布相比，LaPlace 分布将其概率质量集中在更接近零的地方。这个想法是，由于我们有这个零的峰值，我们希望先验能够诱导稀疏性，即，我们创建一个有很多参数的模型，先验会自动使大部分参数为零，只保留对模型输出有贡献的相关变量。不幸的是，贝叶斯拉索并不是真的这样工作的，基本上是因为为了有很多参数，LaPlace 先验是强迫非零参数变小。幸运的是，有一些贝叶斯模型可用于诱导稀疏性和进行变量选择。

![regularization](rethinking/images/ch05/prior-reg.pngpng)

综上，我们可得到 2 条结论

- LSE 误差 + ℓ2 正则项 ≡ 高斯噪声先验下的 MAP 解。
- LSE 误差 + ℓ1 正则项 ≡ LaPlace 噪声先验下的 MAP 解。
