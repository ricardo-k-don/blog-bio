# 高斯混合

当总体是不同亚总体的组合时，自然会产生混合模型。一个非常熟悉的例子是某一成年总体中的身高分布，它可被描述为女性和男性亚总体的混合。若知道每个观测值属于哪个子总体，一般来说，利用这些信息将每个子总体作为一个独立的群体来建模是个好主意。但，当无法直接获得这些信息时，就是混合模型派上用场的时候。

在建立混合模型时，其实并不需要相信描述的是数据中的真实亚总体。混合模型也可作为一种统计技巧来增加工具箱的灵活性。以高斯分布为例，可用它作为许多单模态和或多或少对称分布的合理近似。对于多峰性（multimodal）或倾斜分布，若使用高斯的混合，依然可以。

在高斯混合模型中，每个分量都将是一个高斯，具有不同的均值，通常（但不一定）具有不同的标准差。通过组合高斯，可增加模型的灵活性，以适应复杂的数据分布。事实上，可通过使用适当的高斯型组合来逼近任何想要的分布。分布的确切数量将取决于近似的准确性和数据的细节。核密度估计（Kernel Density Estimation，KDE）技术是这一思想的非贝叶斯（和非参数）实现。

## 1. 有限混合模型

建立混合模型的一种方法是考虑两个或多个分布的有限加权混合。这就是所谓的有限混合模型。故，观测数据的概率密度是数据中$K$个子群的概率密度的加权和。

$$
p(y ∣ θ) = ∑_{i=1}^k w_i p_i(y ∣ θ_i)
$$

其中，$w_i$是每个组分（或类）的权重。可将$w_i$解释为组分$i$的概率，因此它的值被限制在 [\big0, 1\big] 区间内，且$∑_{i=1}^k w_i = 1$。组分$p_i(y  ∣ θ_i)$几乎可是任何认为有用的东西，从简单的分布，如高斯或 Poisson，到更复杂的对象，如层次模型或神经网络。对于有限混合模型，$K$是一个有限的数字（通常但不必须，$K≤ 20$）。为了拟合一个有限混合模型，需要提供一个$K$的值，或是因为真的事先知道正确的值，或是因为有一些有经验的猜测。

### 1.1. 选择分布

从概念上讲，为了求解一个混合模型，需要做的就是将每个数据点正确地分配给其中一个组分。在概率模型中，可通过引入一个随机变量$z$来实现这一目的，它的功能是指定某一特定观测值被分配到哪个组分中。这个变量通常被称为潜变量（latent variable）或隐变量（hidden variable），因为它不能直接被观测。

![chemical shift](rethinking/images/ch10/shift.pngpng)

看到，这些数据无法用一个高斯指数来正确描述，但也许三个或四个高斯指数就可了，这说明数据确实来自于大约 40 个亚总体的混合，但它们之间有相当大的重叠。根据混合模型背后的直觉，可从抛硬币问题中获得思路。对于该模型，有两种可能的结果，使用伯努利分布来描述它们。由于不知道得到头或尾的概率，使用 Beta 分布作为先验。混合模型亦类似，只不过现在有的不是两个结果，如头或尾，而是$K$个结果。

Bernoulli 分布对$K$-组分的泛化是类别分布（Categorical distribution），Beta 分布的泛化是狄利克雷分布（Dirichlet distribution）。

类别分布是最一般的离散分布，它使用一个参数来指定每个可能结果的概率。下图表示类别分布的两种可能的情况。点代表了类别分布的数值，而连续的线条则是一种视觉上的帮助，以帮助掌握分布的形状。

![categorical distribution](rethinking/images/ch10/dist-categorical.pngpng)

狄利克雷分布存在于单形体（simplex）中，满足

$$
\sum_{i=1}^k x_i=1
$$

它就像一个$n$-维的三角形：1-单形体是一条线，2-单形体是一个三角形，3-单形体是一个四面体，以此类推。

![Dirichlet distribution](rethinking/images/ch10/dir-dist.pngpng)

其 PDF 为

$$
f(x)=\frac{1}{\mathrm{B}(\mathbf{α})} ∏_{i=1}^k x_i^{\mathbf{α}_i - 1}
$$

其中，

$$
\mathrm{B}(\mathbf{α}) = \frac{∏_{i=1}^k Γ(\mathbf{α}_i)}{Γ(∑_{i=1}^k \mathbf{α}_i)}
$$

且浓度向量为

$$
\mathbf{α} = (α_1, ⋯, α_k)
$$

### 1.2. 建模

设一个是概率$p$，另一个是$1 - p$。Beta 分布返回一个双元素向量$(p, 1 - p)$，但在实践中，省略了$1 - p$，因为一旦知道$p$，结果就完全决定了。若想将 Beta 分布扩展到三个结果，需要一个三元素向量$(p, q, r)$，其中，每个元素都大于零，$p + q + r = 1$，因此$r = 1 - (p + q)$。

可使用三个标量来参数化这样的分布，可称它们为$α, β, γ$。但，很容易用完希腊字母，因为它们只有 24 个；相反，可只使用一个长度为$K$的$α$向量。这里，可把贝塔和狄利克雷看作是比例的分布。将它们可视化的一种方式是在高斯估计模型上建立一个 K 面抛硬币模型。

![model](rethinking/images/ch10/dir-model2.pngpng)

注意，在混合模型中，观测变量$y$是以潜变量$z$为条件建立模型的。即，$p(y ∣ z, θ)$。可把$z$潜变量看作是一个扰动变量，可对其进行边际化，得到$p(y  ∣ θ)$。由此，上图中的两个模型是等价的。

在不给模型添加变量的情况下，给似然添加的一个任意因子，潜在值（potential）。似然和潜在值的主要区别在于潜在值不一定要依赖于数据，而似然则需要。可使用势来强制执行一个约束条件。例如，可这样定义潜在值，若约束条件没有被违反，就在似然上加一个零的系数；否则，就加一个 -∞ 系数。最终的结果是，模型认为违反约束条件的参数（或参数组合）是不可能的，而模型对其余的值则不加干扰。

![potential](rethinking/images/ch10/dir-model-p.svgsvg)

另一个可能有用的约束条件是确保所有的组分都有一个非空概率，或换句话说，混合中的每个组分至少有一个观测值。

从三元图中可看到，$α$的值控制着狄利克雷分布的浓度。在 `model_mgp` 中使用$α = 1$可得到一个扁平的先验分布。$α$的值越大意味着信息量越大。经验证据表明，$α$ 为 4 或 10 的值通常是一个很好的默认选择，因为这些值通常会导致每个分量至少有一个数据点的后验分布，同时减少高估分量的机会。

![trace](rethinking/images/ch10/dir-trace.pngpng)

### 1.3. 组分数量

有限混合模型的主要问题之一是如何决定组分的数量。一个经验法则是先从相对较少的组分数开始，然后增加组分数，以提高模型拟合度评价。像往常一样，模型拟合度的评估是使用后验预测检查、WAIC 或 LOO 等测量方法，并以建模者的专业知识为基础。

为了更好地显示$K$对推断的影响，要将这些模型的拟合度与使用 `az.plot_kde` 得到的拟合度进行比较。

![Choosing K](rethinking/images/ch10/choosing-k.pngpng)

KDE 图中，黑色实线连同平均拟合较宽（蓝色）线和后半透明（蓝色）线的样本。此外，平均高斯分量使用虚线黑线表示。似乎，$K =3$太低，4、5 或 6 可能是更好的选择。注意到 KDE 预测的峰不则明显（更扁平）。请注意，这并不一定是高斯混合模型的拟合不好，因为 KDE 通常被调整为提供更平滑的密度。你可用直方图代替 KDE，但直方图亦为近似密度的方法。当然，还可计算 PPC 得到$p$值来进行预测。

![PPC](rethinking/images/ch10/choosing-k-ppc.pngpng)

可看到$K =6$是一个很好的选择，其贝叶斯的$p$值非常接近 0.5。而 WAIC 也发现$K =6$是更好的模型

|     | rank |  waic   | p_waic  | d_waic  |   weight    |   se    |   dse   | warning | waic_scale |
| :-: | :--: | :-----: | :-----: | :-----: | :---------: | :-----: | :-----: | :-----: | :--------: |
|  6  |  0   | 10248.4 | 11.9588 |    0    |  0.954816   | 61.0081 |    0    |  False  |  deviance  |
|  5  |  1   | 10258.9 | 10.1009 | 10.4575 |  0.043995   | 60.6531 | 4.98551 |  False  |  deviance  |
|  4  |  2   | 10278.9 | 7.52174 | 30.5034 | 0.00118897  | 59.5172 | 9.95826 |  False  |  deviance  |
|  3  |  3   | 10356.8 | 5.85471 | 108.393 | 1.25734e⁻¹⁴ | 59.6921 | 18.6669 |  False  |  deviance  |

通过绘图可看到，虽然有 6 个组分的模型的 WAIC 比其他模型低，但，当考虑估计的标准误差时，有相当大的重叠，特别是有 5 个组分的模型。

![Choosing K](rethinking/images/ch10/choosing-k-comp.pngpng)

聚类是统计或机器学习任务的无监督家族的一部分，类似于分类，但更困难一些，因为不知道正确的标签。聚类或聚类分析是将对象进行分组的数据分析任务，使某组中的对象比其他组中的对象更接近。这些群组被称为聚类，其紧密程度可通过许多不同的方式来计算；例如，通过使用欧氏距离等指标。若走概率路线，则混合模型就会作为解决聚类任务的自然候选者出现。

使用概率模型进行聚类通常被称为基于模型的聚类。使用概率模型允许计算每个数据点属于每个聚类的概率。这被称为软聚类，与硬聚类相反，在硬聚类中，每个数据点属于一个聚类的概率为 0 或 1。可通过引入一些规则或边界，将软聚类变成硬聚类。对于聚类，合理的选择是将一个数据点分配到概率最高的聚类中。

## 2. 无限混合模型

对于一些问题，例如试图对手写数字进行聚类，很容易证明期望在数据中找到的组数。对于其他问题，可有很好的猜测；例如，可能知道的鸢尾花样本取自一个只生长三种鸢尾花的地区，因此使用三个组分是一个合理的起点。当对分量的数量不是则确定时，可使用模型选择来帮助选择组数。然而对于其他问题来说，先验地选择组数可能是一个缺点，反而对从数据中估计这个数字感兴趣。这类问题的贝叶斯解决方案与狄利克雷过程（Dirichlet process，DP）有关。

### 2.1. 狄利克雷过程

到目前为止，看到的所有模型均是参数模型。这些模型是具有固定数量的参数，感兴趣的估计，如固定数量的聚类。也可有非参数模型，可能这些模型更好的名字是非固定参数模型。非参数模型是理论上参数数量无限的模型。在实践中，以某种方式让数据将理论上无限的参数数量减少到一些有限的数量，换句话说，数据决定了实际的参数数量，因此非参数模型是非常灵活的。

由于狄利克雷分布是 Beta 分布的$n$维泛化，故狄利克雷过程是狄利克雷分布的无穷维泛化。狄利克雷分布是概率空间上的概率分布，而 DP 是分布空间上的概率分布，这意味着从 DP 中抽出的一次抽签实际上就是一个分布。对于有限混合模型，使用狄利克雷分布为固定数量的簇或组分配一个先验。DP 是为非固定数量的群组分配一个先验分布的方法，可把 DP 看成是从先验分布中采样的方法。

DP 的正式定义在某种程度上是晦涩难懂的，除非你对你的概率理论非常了解，故这里仅描述一下 DP 的一些特性，这些特性与理解它在混合模型建模中的作用有关：

- DP 是一个分布，其实现是概率分布。
- DP 由一个基数分布和一个正实数$α$指定，称为浓度参数（类似于狄利克雷分布的浓度参数）。
- $H$是 DP 的期望值，这意味着 DP 将围绕基分布产生分布，这在某种程度上相当于高斯分布的均值。
- 随着$α$的增加，实现越来越不集中。
- 在实践中，DP 总是生成离散的分布。
- 在极限$α → ∞$中，DP 的实现等于基分布，因此若基分布是连续的，DP 将产生一个连续的分布。由于$α$是有限的，数学家们说，从 DP 产生的分布几乎肯定是离散的。

为了使这些特性更加具体，让再看一下类别分布。可通过指明$x$轴上的位置和$y$轴上的高度来完全指定这种分布。对于类别分布，$x$轴上的位置被限制为整数，而高度的总和必须为 1。对于生成$x$轴上的位置，若选择一个高斯分布，原则上位置可是实线上的任何值；若选择一个 Beta 分布，位置将被限制在 [\big0, 1\big] 区间，若选择一个 Poisson 分布，位置将被限制在非负整数${0, 1, 2, …}$。

### 2.2. 断棒过程

如何选择$y$轴上的值呢？按照一个思想实验（Gedankenexperiment），即所谓的断棒过程（stick-breaking process）。想象一下，有一根长度为 1 的棍子，然后把它掰成两部分（不一定相等）。把其中的一部分放在一边，然后把另一部分掰成两部分，然后就一直这样做下去。在实践中，由于不能真正无限地重复这个过程，故将其截断在某个预定义的$K$值上，但一般的想法是成立的。为了控制棍子的断裂过程，使用了一个参数$α$，当增加$α$的值时，将把棍子断成越来越小的部分。因此在$\underset{α → 0}{\lim}$中，将不会对棍子进行制动，而当$\underset{α → ∞}{\lim}$中，将把棍子掰成无限的碎片。下图显示了在$α$的四个不同值的情况下，从一个 DP 中抽出的四次样本。

![stick- breaking](rethinking/images/ch10/stick.pngpng)

可看到，DP 是一个离散分布。当$α$增加时，得到的是一个更分散的分布和更小的棍子，注意到$y$轴的比例变化，记住总长度固定在$1$。基准分布控制着位置，因为位置是从基准分布中抽取的，随着$α$的增加，DP 分布的形状越来越像基数分布$H$。在$\underset{α → ∞}{\lim}$中，应该准确地得到基数分布。

有限混合显示，若在每个数据点上放置一个高斯，然后将所有高斯相加，就可近似地计算出数据的分布。可使用 DP 来做类似的事情，但不是在每个数据点上放置一个高斯，而是在 DP 实现的每个子棍的位置上放置一个高斯，然后通过该子棍的长度来缩放或加权该高斯。这个过程提供了一个无限高斯混合模型的一般配方。另外，也可将高斯替换为任何其他分布，这样就有了一个通用的无限混合模型的配方。

下面，使用 LaPlace 分布的混合给出一个例子。

![LaPlace mixture](rethinking/images/ch10/lapmm.pngpng)

从数学上看，DP 的断棒过程视图可用下面的方式来表示

$$
∑_{k=1}^{∞} w_k ⋅ δ_{θ_k}(θ) = f(θ) ∼ D P(α, H)
$$

其中，

- $δ_{θ_k}$是指标函数，它将$i$评价为零，除了$δ_{θ_k}(θ_k) = 1$，这代表了从基本分布$H$中采样的位置。
- 概率$w_k$由以下公式给出

$$
w_k = β_k' ⋅∏_{i=1}^{k-1}(1 - β_i')
$$

其中，

- $w_k$是一个子棍的长度。
- $∏_{i=1}^{k-1}(1 - β_i')$是剩余部分的长度，也就是需要不断打破的部分。
- $β_k'$表示如何打破剩余的部分。
  $ρ_k' ∼ \mathrm{Beta}(1, α)$，从这个表达式中可看出，当$α$增加时$β_k'$将平均变小。

让为浓度参数$α$定义一个先验。一个常见的选择是伽马分布。

![stick- breaking](rethinking/images/ch10/stick-trace.pngpng)

从下图中可看到，$α$的值相当低，这说明描述数据所需的分量很少。因为是通过截断棒断程序来近似于无限 DP，故检查截断值（$K =20$）是否没有引入任何偏差是很重要的。一个简单的方法是绘制每个组件的平均权重，为了安全起见，应该有几个组件的权重可忽略不计，否则必须增加截断值。可看到，只有少数的第一个分量是重要的，因此可相信所选择的上值$K =20$对于这个模型和数据来说是足够大的。

![stick- breaking](rethinking/images/ch10/stick-k.pngpng)

下图显示了使用 DP 模型（黑色）线估计的平均密度，以及后验（灰色）线的样本，以反映估计的不确定性。与之前模型的 KDE 相比，该模型的密度也不太平稳。

![KDE](rethinking/images/ch10/stick-kde.pngpng)

## 3. 连续混合模型

之前的稳健逻辑回归模型，那个模型是两部分的混合：一方面是逻辑回归，另一方面是随机猜测。请注意，这个参数并不是一个开/关开关，而是更像是一个混合旋钮，控制在旋钮中有多少随机猜测和多少逻辑回归。只有对于极端值，才会有纯随机猜测或纯逻辑回归。

层次模型也可解释为连续混合模型，每组的参数都来自上层的连续分布。为了更具体，可考虑对几个组进行线性回归。可设每个组都有自己的斜率，或所有组都有相同的斜率。另外，与其将的问题框定为两个极端和离散的选项，分层模型允许有效地对这些极端选项的连续混合进行建模，因此极端选项只是这个更大的分层模型的特殊情况。

### 3.1. 贝塔 - 二项分布

贝塔 - 二项分布是一个离散分布，一般用于描述当每次试验的成功概率$p$是未知时，$n$次伯努利试验的成功次数$y$，并设遵循参数$α$和$β$的 Beta 分布。

$$
\mathrm{BetaB}(y ∣ n, α, β) = ∫_0\mathrm{B}(y ∣ p, n) \mathrm{Beta}(p |α, β) dp
$$

即，为了找到观察到结果$y$的概率，对$p$的所有可能的（和连续的）值进行平均，因此贝塔 - 二项分布可被认为是一个连续的混合模型。这就是用于解决抛硬币问题的模型，不过明确使用的是贝塔和二项分布，而不是使用已经混合的 β -二项分布。

### 3.2. 负二项分布

负二项分布，可理解为伽马-Poisson 混合。对于这个模型，有一个 Poisson 分布的混合，其中，速率参数是伽马分布。这种分布经常被用于规避处理计数数据时遇到的一个常见问题。这个问题被称为过度分散（over-dispersion）。设你正在使用 Poisson 分布对计数数据进行建模，然后你意识到你的数据中的方差超过了模型的方差；使用 Poisson 分布的问题是均值和方差是联系在一起的（事实上它们是由同一个参数描述的）。故，解决这个问题的一种方法是将数据建模为一个（连续的）Poisson 分布的混合，其速率来自一个伽马分布，这就给了使用负二项分布的理由。由于现在考虑的是分布的混合，的模型具有更大的灵活性，可更好地适应观察到的数据的均值和方差。

> 贝塔 - 二项分布和负二项分布都可作为线性模型的一部分，且，两者也都有零膨胀的版本。

### 3.3. 学生 _t_ 分布

引入学生 _t_ 分布作为高斯分布的稳健替代。事实证明，学生 _t_ 分布也可被认为是一个连续的混合物。在这种情况下，有

$$
t_{ν}(y ∣ μ, σ) = ∫_0^{∞} N(y ∣ μ, σ) \mathrm{Inv} χ^2(σ |ν) dν
$$

请注意，这与之前的负二项式表达式类似，只是这里有一个参数为$μ$和$σ$的高斯分布，以及参数为$ν$的逆$χ^2$分布，从中抽取$σ$的值，这个参数被称为自由度，或更愿意称之为正态性参数。参数$ν$，以及贝塔 - 二项分布的$p$，相当于有限混合模型的$z$潜变量。对于一些有限混合模型，也可在推理之前对潜变量的分布进行边际化，这可能会带来一个更容易采样的模型。
